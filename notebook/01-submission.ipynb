{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3753477d",
   "metadata": {
    "papermill": {
     "duration": 0.019209,
     "end_time": "2023-04-01T04:55:41.801856",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.782647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# [W&B] American Sign Language Detection"
   ]
  },
  {
   "attachments": {
    "7e068ada-ac98-4392-af47-eecf8c4412de.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ef83c97f",
   "metadata": {
    "papermill": {
     "duration": 0.018139,
     "end_time": "2023-04-01T04:55:41.840333",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.822194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image.png](attachment:7e068ada-ac98-4392-af47-eecf8c4412de.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8f15f",
   "metadata": {
    "papermill": {
     "duration": 0.017772,
     "end_time": "2023-04-01T04:55:41.876406",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.858634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eceb109",
   "metadata": {
    "papermill": {
     "duration": 0.017714,
     "end_time": "2023-04-01T04:55:41.912403",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.894689",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello and welcome all to my first Kaggle notebook in a few years. Generally I write blog posts - the most recent ones being on [CLIP](https://amaarora.github.io/posts/2023-03-11_Understanding_CLIP_part_2.html), but have recently taken an interest into Kaggle. The idea is to create clear concise high scoring notebooks to share with all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509e367",
   "metadata": {
    "papermill": {
     "duration": 0.017915,
     "end_time": "2023-04-01T04:55:41.948168",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.930253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I started competing in this competition about 2 weeks ago and have spent few hours every day for the past few weeks experimenting on this competition. I hadn't used Tensorflow or Keras before this competition - so want to take my time to thank all the Kagglers who have openly shared their solutions. Since, I learnt from you all, I am sharing my solution too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb802508",
   "metadata": {
    "papermill": {
     "duration": 0.030533,
     "end_time": "2023-04-01T04:55:41.996228",
     "exception": false,
     "start_time": "2023-04-01T04:55:41.965695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As part of this notebook I will also share my learnings based on the experiments so far and also possible ideas that could potentially make the solution even better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4196c",
   "metadata": {
    "papermill": {
     "duration": 0.035538,
     "end_time": "2023-04-01T04:55:42.070596",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.035058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> At the time of writing, this notebook has the highest score on public leaderboard and ranks $48/709$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce28b18",
   "metadata": {
    "papermill": {
     "duration": 0.030306,
     "end_time": "2023-04-01T04:55:42.131108",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.100802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you'd like to team up and work in the ideas that I have shared in this notebook, feel free to reach out to me. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5f76e",
   "metadata": {
    "papermill": {
     "duration": 0.02702,
     "end_time": "2023-04-01T04:55:42.184963",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.157943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a755ee",
   "metadata": {
    "papermill": {
     "duration": 0.02588,
     "end_time": "2023-04-01T04:55:42.237144",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.211264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Thank you @markwijkhuizen for your highest scoring single Transformer model [notebook [LB 0.67]](https://www.kaggle.com/code/markwijkhuizen/gislr-tf-data-processing-transformer-training). \n",
    "2. Thank you @roberthatch for sharing [how to create features](https://www.kaggle.com/code/roberthatch/gislr-lb-0-63-on-the-shoulders) that have time information in them. IMHO, you have uplifted this competition as many other high scoring notebooks have been based on your feature set after. I myself tried over 60 different experiments on top of the notebook that you shared. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739582bf",
   "metadata": {
    "papermill": {
     "duration": 0.025799,
     "end_time": "2023-04-01T04:55:42.290393",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.264594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Experiment Tracking using Weights and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23cb15",
   "metadata": {
    "papermill": {
     "duration": 0.026428,
     "end_time": "2023-04-01T04:55:42.342993",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.316565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I used [Weights and Biases](https://wandb.ai/) for experiment tracking. I ran a total of **83 different experiments** which I tracked using W&B. As part of this notebook I will also share my learnings from those experiments. \n",
    "\n",
    "Weights & Biases is the machine learning platform for developers to build better models faster. Use W&B's lightweight, interoperable tools to quickly track experiments, version and iterate on datasets, evaluate model performance, reproduce models, visualize results and spot regressions, and share findings with colleagues.\n",
    "\n",
    "> For a quickstart on W&B, refer **[HERE](http://wandb.me/aman)**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519691e",
   "metadata": {
    "papermill": {
     "duration": 0.025933,
     "end_time": "2023-04-01T04:55:42.395283",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.369350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![img](https://raw.githubusercontent.com/amaarora/amaarora.github.io/master/images/kaggle_nb_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e634fef",
   "metadata": {
    "papermill": {
     "duration": 0.026305,
     "end_time": "2023-04-01T04:55:42.447597",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.421292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To access all my experiments - refer [here](https://wandb.ai/amanarora/asl-sings?workspace=user-amanarora).\n",
    "\n",
    "As part of these experiments I tried a wide range of learning rates, model architectures, dataset features. I hope that the information I share here will be helpful to you in creating a winning solution.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94df9e",
   "metadata": {
    "papermill": {
     "duration": 0.027292,
     "end_time": "2023-04-01T04:55:42.500838",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.473546",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, with credits and introductions out of the way, let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb2390",
   "metadata": {
    "papermill": {
     "duration": 0.022488,
     "end_time": "2023-04-01T04:55:42.554722",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.532234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49dc937",
   "metadata": {
    "papermill": {
     "duration": 0.017496,
     "end_time": "2023-04-01T04:55:42.590192",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.572696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To be able to use trained model weights, please create a wandb API key and paste below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc650c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:42.627632Z",
     "iopub.status.busy": "2023-04-01T04:55:42.627110Z",
     "iopub.status.idle": "2023-04-01T04:55:50.873773Z",
     "shell.execute_reply": "2023-04-01T04:55:50.872492Z"
    },
    "papermill": {
     "duration": 8.268569,
     "end_time": "2023-04-01T04:55:50.876729",
     "exception": false,
     "start_time": "2023-04-01T04:55:42.608160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json, random, math, scipy, wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold \n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb2efa",
   "metadata": {
    "papermill": {
     "duration": 0.017722,
     "end_time": "2023-04-01T04:55:50.914208",
     "exception": false,
     "start_time": "2023-04-01T04:55:50.896486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa111b9d",
   "metadata": {
    "papermill": {
     "duration": 0.017701,
     "end_time": "2023-04-01T04:55:50.949735",
     "exception": false,
     "start_time": "2023-04-01T04:55:50.932034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is important to be able to test the models, since as part of this competition we only submit a `submission.zip` file that contains `model.tflite`, it is important to check that the model is working before submitting to the competition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd305a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:50.988154Z",
     "iopub.status.busy": "2023-04-01T04:55:50.986619Z",
     "iopub.status.idle": "2023-04-01T04:55:50.993504Z",
     "shell.execute_reply": "2023-04-01T04:55:50.992520Z"
    },
    "papermill": {
     "duration": 0.028252,
     "end_time": "2023-04-01T04:55:50.995652",
     "exception": false,
     "start_time": "2023-04-01T04:55:50.967400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/competitions/asl-signs/overview/evaluation\n",
    "ROWS_PER_FRAME = 543\n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab17279",
   "metadata": {
    "papermill": {
     "duration": 0.017335,
     "end_time": "2023-04-01T04:55:51.030852",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.013517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above code from the evaluation page showcases how the test data is loaded in the competition. So if it works on our model, we can be rest assured that our submission won't fail (unless it times out..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6bd69f",
   "metadata": {
    "papermill": {
     "duration": 0.017957,
     "end_time": "2023-04-01T04:55:51.066529",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.048572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model-1 Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c21165",
   "metadata": {
    "papermill": {
     "duration": 0.018983,
     "end_time": "2023-04-01T04:55:51.103183",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.084200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First, we get started with the transformer model from the amazing [GISLR TF Data Processing & Transformer Training](https://www.kaggle.com/code/markwijkhuizen/gislr-tf-data-processing-transformer-training) notebook by [Mark Wijkhuizen](https://www.kaggle.com/markwijkhuizen). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cd33c",
   "metadata": {
    "papermill": {
     "duration": 0.017582,
     "end_time": "2023-04-01T04:55:51.138552",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.120970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The only difference between our version and the original version is that we trained the model on the whole dataset instead of just the training dataset as in the original notebook. *The single model trained on complete dataset is able to achieve a score of 0.68 on the public leaderboard.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa60157",
   "metadata": {
    "papermill": {
     "duration": 0.017337,
     "end_time": "2023-04-01T04:55:51.173541",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.156204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Config and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1719d6ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.211668Z",
     "iopub.status.busy": "2023-04-01T04:55:51.210619Z",
     "iopub.status.idle": "2023-04-01T04:55:51.215660Z",
     "shell.execute_reply": "2023-04-01T04:55:51.214542Z"
    },
    "papermill": {
     "duration": 0.026201,
     "end_time": "2023-04-01T04:55:51.217810",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.191609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SimpleNamespace()はオブジェクトと違って、attributeを追加削除できる\n",
    "cfg = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "238c4a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.255923Z",
     "iopub.status.busy": "2023-04-01T04:55:51.255556Z",
     "iopub.status.idle": "2023-04-01T04:55:51.260319Z",
     "shell.execute_reply": "2023-04-01T04:55:51.259334Z"
    },
    "papermill": {
     "duration": 0.026844,
     "end_time": "2023-04-01T04:55:51.262584",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.235740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kaggleの環境で走っている確認\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991d3510",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.302293Z",
     "iopub.status.busy": "2023-04-01T04:55:51.301362Z",
     "iopub.status.idle": "2023-04-01T04:55:51.306980Z",
     "shell.execute_reply": "2023-04-01T04:55:51.305825Z"
    },
    "papermill": {
     "duration": 0.027357,
     "end_time": "2023-04-01T04:55:51.309024",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.281667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR         = Path('../data/') if not iskaggle else Path('/kaggle/input/asl-signs/')\n",
    "TRAIN_CSV_PATH   = DATA_DIR/'train.csv'\n",
    "LANDMARK_DIR     = DATA_DIR/'train_landmark_files'\n",
    "LABEL_MAP_PATH   = DATA_DIR/'sign_to_prediction_index_map.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53cf5c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.346706Z",
     "iopub.status.busy": "2023-04-01T04:55:51.346276Z",
     "iopub.status.idle": "2023-04-01T04:55:51.353156Z",
     "shell.execute_reply": "2023-04-01T04:55:51.352068Z"
    },
    "papermill": {
     "duration": 0.027804,
     "end_time": "2023-04-01T04:55:51.355218",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.327414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg.PREPROCESS_DATA = False\n",
    "cfg.TRAIN_MODEL = False\n",
    "cfg.N_ROWS = 543\n",
    "cfg.N_DIMS = 3\n",
    "cfg.DIM_NAMES = ['x', 'y', 'z']\n",
    "cfg.SEED = 42\n",
    "cfg.NUM_CLASSES = 250\n",
    "cfg.IS_INTERACTIVE = True\n",
    "cfg.VERBOSE = 2\n",
    "cfg.INPUT_SIZE = 32\n",
    "cfg.BATCH_ALL_SIGNS_N = 4\n",
    "cfg.BATCH_SIZE = 256\n",
    "cfg.N_EPOCHS = 50\n",
    "cfg.LR_MAX = 1e-3\n",
    "cfg.N_WARMUP_EPOCHS = 0\n",
    "cfg.WD_RATIO = 0.05\n",
    "cfg.MASK_VAL = 4237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a6f257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.392324Z",
     "iopub.status.busy": "2023-04-01T04:55:51.391963Z",
     "iopub.status.idle": "2023-04-01T04:55:51.581486Z",
     "shell.execute_reply": "2023-04-01T04:55:51.580388Z"
    },
    "papermill": {
     "duration": 0.211264,
     "end_time": "2023-04-01T04:55:51.584029",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.372765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94477"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Training Data\n",
    "train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "N_SAMPLES = len(train)\n",
    "N_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cac4c",
   "metadata": {
    "papermill": {
     "duration": 0.017704,
     "end_time": "2023-04-01T04:55:51.619898",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.602194",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, instead of updating the path on the train file, we create a symlink instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b15ef2be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:51.658764Z",
     "iopub.status.busy": "2023-04-01T04:55:51.657179Z",
     "iopub.status.idle": "2023-04-01T04:55:52.639000Z",
     "shell.execute_reply": "2023-04-01T04:55:52.637664Z"
    },
    "papermill": {
     "duration": 1.00358,
     "end_time": "2023-04-01T04:55:52.641523",
     "exception": false,
     "start_time": "2023-04-01T04:55:51.637943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign                                      file_path  \n",
       "0   blow  train_landmark_files/26734/1000035562.parquet  \n",
       "1   wait  train_landmark_files/28656/1000106739.parquet  \n",
       "2  cloud   train_landmark_files/16069/100015657.parquet  \n",
       "3   bird  train_landmark_files/25571/1000210073.parquet  \n",
       "4   owie  train_landmark_files/62590/1000240708.parquet  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'/kaggle/input/asl-signs/{path}'\n",
    "\n",
    "!ln -s {LANDMARK_DIR} ./train_landmark_files\n",
    "train['file_path'] = train['path'].values  # pathカラムと同じカラムをfile_pathカラムに作る\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e420a4",
   "metadata": {
    "papermill": {
     "duration": 0.017978,
     "end_time": "2023-04-01T04:55:52.678089",
     "exception": false,
     "start_time": "2023-04-01T04:55:52.660111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, as in the original notebook, we convert the sign to a category and convert sign to codes and assign it as `sign_org`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6538df7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:52.716214Z",
     "iopub.status.busy": "2023-04-01T04:55:52.715821Z",
     "iopub.status.idle": "2023-04-01T04:55:52.886257Z",
     "shell.execute_reply": "2023-04-01T04:55:52.884971Z"
    },
    "papermill": {
     "duration": 0.193,
     "end_time": "2023-04-01T04:55:52.888996",
     "exception": false,
     "start_time": "2023-04-01T04:55:52.695996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['sign_ord'] = train['sign'].astype('category').cat.codes\n",
    "SIGN2ORD = train[['sign', 'sign_ord']].set_index('sign').squeeze().to_dict()\n",
    "ORD2SIGN = train[['sign_ord', 'sign']].set_index('sign_ord').squeeze().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3736ee",
   "metadata": {
    "papermill": {
     "duration": 0.018006,
     "end_time": "2023-04-01T04:55:52.925774",
     "exception": false,
     "start_time": "2023-04-01T04:55:52.907768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I am not sure why the author did this, could have also used the mapping provided to us in the competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5db75",
   "metadata": {
    "papermill": {
     "duration": 0.018119,
     "end_time": "2023-04-01T04:55:52.962038",
     "exception": false,
     "start_time": "2023-04-01T04:55:52.943919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f02a70",
   "metadata": {
    "papermill": {
     "duration": 0.034428,
     "end_time": "2023-04-01T04:55:53.024325",
     "exception": false,
     "start_time": "2023-04-01T04:55:52.989897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Below, we create K-folds using `StratifiedGroupKFold`, the idea  is to have different participants in train and validation. This mimics the test scenario better compared to a random train-test-split IMHO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9436f8ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.098125Z",
     "iopub.status.busy": "2023-04-01T04:55:53.097648Z",
     "iopub.status.idle": "2023-04-01T04:55:53.103070Z",
     "shell.execute_reply": "2023-04-01T04:55:53.101965Z"
    },
    "papermill": {
     "duration": 0.046733,
     "end_time": "2023-04-01T04:55:53.105772",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.059039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add33af8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.161955Z",
     "iopub.status.busy": "2023-04-01T04:55:53.161524Z",
     "iopub.status.idle": "2023-04-01T04:55:53.173944Z",
     "shell.execute_reply": "2023-04-01T04:55:53.172946Z"
    },
    "papermill": {
     "duration": 0.043291,
     "end_time": "2023-04-01T04:55:53.176699",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.133408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.participant_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85de99a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.235187Z",
     "iopub.status.busy": "2023-04-01T04:55:53.234642Z",
     "iopub.status.idle": "2023-04-01T04:55:53.671695Z",
     "shell.execute_reply": "2023-04-01T04:55:53.670516Z"
    },
    "papermill": {
     "duration": 0.469034,
     "end_time": "2023-04-01T04:55:53.674320",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.205286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sign_ord</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>164</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "\n",
       "    sign                                      file_path  sign_ord  fold  \n",
       "0   blow  train_landmark_files/26734/1000035562.parquet        25     3  \n",
       "1   wait  train_landmark_files/28656/1000106739.parquet       232     0  \n",
       "2  cloud   train_landmark_files/16069/100015657.parquet        48     3  \n",
       "3   bird  train_landmark_files/25571/1000210073.parquet        23     1  \n",
       "4   owie  train_landmark_files/62590/1000240708.parquet       164     5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_PARTICIPANTS = train.participant_id.nunique()\n",
    "sgkf = StratifiedGroupKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "train['fold'] = -1\n",
    "# .splitでfoldごとのインデックスリストが帰ってくる .split(X, y, groups) -> participantごとにfoldする\n",
    "for i, (train_idx, val_idx) in enumerate(sgkf.split(train.index, train.sign, train.participant_id)):\n",
    "    train.loc[val_idx, 'fold'] = i  # trainの各行にfoldの数を入れる\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91e7fca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.713494Z",
     "iopub.status.busy": "2023-04-01T04:55:53.712424Z",
     "iopub.status.idle": "2023-04-01T04:55:53.738223Z",
     "shell.execute_reply": "2023-04-01T04:55:53.737183Z"
    },
    "papermill": {
     "duration": 0.047945,
     "end_time": "2023-04-01T04:55:53.740793",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.692848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create indexes using fold `0` for now\n",
    "# foldが0以外がtrainデータ、flodが0がvalデータ\n",
    "train_idxs = train.query(\"fold!=0\").index.values\n",
    "val_idxs = train.query(\"fold==0\").index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "935f2e3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.780783Z",
     "iopub.status.busy": "2023-04-01T04:55:53.779706Z",
     "iopub.status.idle": "2023-04-01T04:55:53.786935Z",
     "shell.execute_reply": "2023-04-01T04:55:53.785864Z"
    },
    "papermill": {
     "duration": 0.028978,
     "end_time": "2023-04-01T04:55:53.789119",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.760141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80610, 13867)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idxs), len(val_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28fcaa",
   "metadata": {
    "papermill": {
     "duration": 0.018925,
     "end_time": "2023-04-01T04:55:53.826509",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.807584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Process Data Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fc06dd",
   "metadata": {
    "papermill": {
     "duration": 0.018793,
     "end_time": "2023-04-01T04:55:53.878781",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.859988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we copy the `PreprocessLayer` as from the original notebook - https://www.kaggle.com/code/roberthatch/gislr-lb-0-63-on-the-shoulders with some pre-defined variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc6004",
   "metadata": {
    "papermill": {
     "duration": 0.018699,
     "end_time": "2023-04-01T04:55:53.916899",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.898200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> One thing I noted, the pose indices - they have values `np.arange(502, 512)`, is this right? Shouldn't this be `np.arange(489,522)`? Something for you to experiment. :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9597db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:53.957032Z",
     "iopub.status.busy": "2023-04-01T04:55:53.956408Z",
     "iopub.status.idle": "2023-04-01T04:55:53.967076Z",
     "shell.execute_reply": "2023-04-01T04:55:53.966058Z"
    },
    "papermill": {
     "duration": 0.032946,
     "end_time": "2023-04-01T04:55:53.969199",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.936253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92,\n",
       " array([ 61, 185,  40,  39,  37,   0, 267, 269, 270, 409, 291, 146,  91,\n",
       "        181,  84,  17, 314, 405, 321, 375,  78, 191,  80,  81,  82,  13,\n",
       "        312, 311, 310, 415,  95,  88, 178,  87,  14, 317, 402, 318, 324,\n",
       "        308, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
       "        480, 481, 482, 483, 484, 485, 486, 487, 488, 522, 523, 524, 525,\n",
       "        526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
       "        539, 540, 541, 542, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
       "        511]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# landmark indices in original data\n",
    "LIPS_IDXS0 = np.array([\n",
    "        61, 185, 40, 39, 37, 0, 267, 269, 270, 409,\n",
    "        291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "        78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "        95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "    ])\n",
    "LEFT_HAND_IDXS0  = np.arange(468,489)\n",
    "RIGHT_HAND_IDXS0 = np.arange(522,543)\n",
    "POSE_IDXS0       = np.arange(502, 512)\n",
    "LANDMARK_IDXS0   = np.concatenate((LIPS_IDXS0, LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0, POSE_IDXS0))\n",
    "HAND_IDXS0       = np.concatenate((LEFT_HAND_IDXS0, RIGHT_HAND_IDXS0), axis=0)\n",
    "N_COLS           = LANDMARK_IDXS0.size\n",
    "N_COLS, LANDMARK_IDXS0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "186fd7f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:54.008493Z",
     "iopub.status.busy": "2023-04-01T04:55:54.008077Z",
     "iopub.status.idle": "2023-04-01T04:55:54.015973Z",
     "shell.execute_reply": "2023-04-01T04:55:54.014929Z"
    },
    "papermill": {
     "duration": 0.029957,
     "end_time": "2023-04-01T04:55:54.018188",
     "exception": false,
     "start_time": "2023-04-01T04:55:53.988231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Landmark indices in processed data\n",
    "# np.isin(array1, array2) -> array1の要素がarray2の要素の中にあったらそこはTrueになる、それ以外はFalse\n",
    "# np.argwhere(array) 値が0以外の要素のインデックスの組を返す (Trueのインデックスを返す)\n",
    "# 各インデックスが入っている\n",
    "LIPS_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, LIPS_IDXS0)).squeeze() \n",
    "LEFT_HAND_IDXS  = np.argwhere(np.isin(LANDMARK_IDXS0, LEFT_HAND_IDXS0)).squeeze()\n",
    "RIGHT_HAND_IDXS = np.argwhere(np.isin(LANDMARK_IDXS0, RIGHT_HAND_IDXS0)).squeeze()\n",
    "HAND_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, HAND_IDXS0)).squeeze()\n",
    "POSE_IDXS       = np.argwhere(np.isin(LANDMARK_IDXS0, POSE_IDXS0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b36d975d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:54.058373Z",
     "iopub.status.busy": "2023-04-01T04:55:54.057698Z",
     "iopub.status.idle": "2023-04-01T04:55:54.064601Z",
     "shell.execute_reply": "2023-04-01T04:55:54.063372Z"
    },
    "papermill": {
     "duration": 0.029668,
     "end_time": "2023-04-01T04:55:54.066957",
     "exception": false,
     "start_time": "2023-04-01T04:55:54.037289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIPS_IDXS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b32afe",
   "metadata": {
    "papermill": {
     "duration": 0.018852,
     "end_time": "2023-04-01T04:55:54.104959",
     "exception": false,
     "start_time": "2023-04-01T04:55:54.086107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the function below, if I am to explain it in my own words: \n",
    "\n",
    "We pad the input video data (out from `load_relevant_data_subset`) to `cfg.INPUT_SIZE #32` frames if number of frames is lower than `cfg.INPUT_SIZE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16d63b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:54.144579Z",
     "iopub.status.busy": "2023-04-01T04:55:54.143646Z",
     "iopub.status.idle": "2023-04-01T04:55:56.479459Z",
     "shell.execute_reply": "2023-04-01T04:55:56.478342Z"
    },
    "papermill": {
     "duration": 2.358017,
     "end_time": "2023-04-01T04:55:56.481822",
     "exception": false,
     "start_time": "2023-04-01T04:55:54.123805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([4, 4, 4], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.repeat([4], repeats=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a587404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:56.523982Z",
     "iopub.status.busy": "2023-04-01T04:55:56.523550Z",
     "iopub.status.idle": "2023-04-01T04:55:56.548003Z",
     "shell.execute_reply": "2023-04-01T04:55:56.546882Z"
    },
    "papermill": {
     "duration": 0.049539,
     "end_time": "2023-04-01T04:55:56.550575",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.501036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PreprocessLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def pad_edge(self, t, repeats, side):\n",
    "        if side == 'LEFT':\n",
    "            return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
    "        elif side == 'RIGHT':\n",
    "            return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n",
    "    \n",
    "    @tf.function(\n",
    "        input_signature=(tf.TensorSpec(shape=[None,cfg.N_ROWS,cfg.N_DIMS], dtype=tf.float32),),\n",
    "    )\n",
    "    def call(self, data0):\n",
    "        # Number of Frames in Video\n",
    "        N_FRAMES0 = tf.shape(data0)[0]\n",
    "        \n",
    "        # Keep only non-empty frames in data\n",
    "        # numpy.nanmean()でNaNを無視した平均値を返す\n",
    "        # tf.gather(params, indices) -> indicesに応じて、paramsから値を取り出してくる\n",
    "        # handのデータの平均値\n",
    "        frames_hands_nansum = tf.experimental.numpy.nanmean(tf.gather(data0, HAND_IDXS0, axis=1), axis=[1,2])\n",
    "        # tf.where(condition) -> conditionがTrueの要素のインデックスを返す\n",
    "        # 平均値が0より大きいデータ(空でないデータ）のインデックス \n",
    "        non_empty_frames_idxs = tf.where(frames_hands_nansum > 0)\n",
    "        non_empty_frames_idxs = tf.squeeze(non_empty_frames_idxs, axis=1)\n",
    "        # 空でないデータだけ取り出す\n",
    "        data = tf.gather(data0, non_empty_frames_idxs, axis=0)\n",
    "        \n",
    "        non_empty_frames_idxs = tf.cast(non_empty_frames_idxs, tf.float32) \n",
    "        \n",
    "        # Number of non-empty frames 空でないデータのフレーム数\n",
    "        N_FRAMES = tf.shape(data)[0]\n",
    "        # landmarkのインデックスに応じてそのデータだけを取り出す\n",
    "        data = tf.gather(data, LANDMARK_IDXS0, axis=1)\n",
    "        \n",
    "        # 使えるフレーム数が、インプットサイズより小さい時\n",
    "        if N_FRAMES < cfg.INPUT_SIZE:\n",
    "            # Video fits in cfg.INPUT_SIZE\n",
    "            # tf.pad()　でテンソルに対してパディングができる\n",
    "            # inputsizeに満たしいない部分は-1でパディングする\n",
    "            non_empty_frames_idxs = tf.pad(non_empty_frames_idxs, [[0, cfg.INPUT_SIZE-N_FRAMES]], constant_values=-1)\n",
    "            # inputsizeに満たしいない部分は0でパディングする\n",
    "            data = tf.pad(data, [[0, cfg.INPUT_SIZE-N_FRAMES], [0,0], [0,0]], constant_values=0)\n",
    "            # tf.math.is_nan() nanの要素はTrueで帰ってくる　そうでない要素はFalse\n",
    "            # nanの場合は0そうでない場合はそのままの値にする\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            return data, non_empty_frames_idxs\n",
    "        else:# インプットサイズ以上の場合はサイズをおとす\n",
    "            # Video needs to be downsampled to cfg.INPUT_SIZE\n",
    "            # 2倍よりも小さいなら\n",
    "            if N_FRAMES < cfg.INPUT_SIZE**2:\n",
    "                # tf.math.floordiv(x, y) -> x / yを要素ごとにおこなう //と等しい\n",
    "                # 何回繰り返せば良いか\n",
    "                repeats = tf.math.floordiv(cfg.INPUT_SIZE * cfg.INPUT_SIZE, N_FRAMES0)\n",
    "                # 繰り返し回数だけくりかしてデータを入れる\n",
    "                data = tf.repeat(data, repeats=repeats, axis=0)\n",
    "                non_empty_frames_idxs = tf.repeat(non_empty_frames_idxs, repeats=repeats, axis=0)\n",
    "\n",
    "            # Pad To Multiple Of Input Size\n",
    "            # 全データから何個パッチが作れるか pool_sizseはパッチの個数\n",
    "            pool_size = tf.math.floordiv(len(data), cfg.INPUT_SIZE)\n",
    "            # tf.math.mod(x, y) -> x/yの余りを返す\n",
    "            # パッチを等しく分けれない時\n",
    "            if tf.math.mod(len(data), cfg.INPUT_SIZE) > 0:\n",
    "                # パッチのサイズを一個増やす\n",
    "                pool_size += 1\n",
    "            # パッチのサイズがたった1この時\n",
    "            if pool_size == 1:\n",
    "                pad_size = (pool_size * cfg.INPUT_SIZE) - len(data)\n",
    "            else:\n",
    "                # padサイズは最後のパッチのサイズ\n",
    "                pad_size = (pool_size * cfg.INPUT_SIZE) % len(data)\n",
    "\n",
    "            # Pad Start/End with Start/End value\n",
    "            pad_left = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(cfg.INPUT_SIZE, 2)\n",
    "            pad_right = tf.math.floordiv(pad_size, 2) + tf.math.floordiv(cfg.INPUT_SIZE, 2)\n",
    "            if tf.math.mod(pad_size, 2) > 0:\n",
    "                pad_right += 1\n",
    "\n",
    "            # Pad By Concatenating Left/Right Edge Values\n",
    "            data = self.pad_edge(data, pad_left, 'LEFT')\n",
    "            data = self.pad_edge(data, pad_right, 'RIGHT')\n",
    "\n",
    "            # Pad Non Empty Frame Indices\n",
    "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_left, 'LEFT')\n",
    "            non_empty_frames_idxs = self.pad_edge(non_empty_frames_idxs, pad_right, 'RIGHT')\n",
    "\n",
    "            # Reshape to Mean Pool\n",
    "            data = tf.reshape(data, [cfg.INPUT_SIZE, -1, N_COLS, cfg.N_DIMS])\n",
    "            non_empty_frames_idxs = tf.reshape(non_empty_frames_idxs, [cfg.INPUT_SIZE, -1])\n",
    "\n",
    "            # Mean Pool\n",
    "            data = tf.experimental.numpy.nanmean(data, axis=1)\n",
    "            non_empty_frames_idxs = tf.experimental.numpy.nanmean(non_empty_frames_idxs, axis=1)\n",
    "\n",
    "            # Fill NaN Values With 0\n",
    "            data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "            \n",
    "            return data, non_empty_frames_idxs\n",
    "    \n",
    "preprocess_layer = PreprocessLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfac0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:56.590393Z",
     "iopub.status.busy": "2023-04-01T04:55:56.590032Z",
     "iopub.status.idle": "2023-04-01T04:55:56.601428Z",
     "shell.execute_reply": "2023-04-01T04:55:56.600339Z"
    },
    "papermill": {
     "duration": 0.033892,
     "end_time": "2023-04-01T04:55:56.603682",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.569790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.mod(5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843f0e6",
   "metadata": {
    "papermill": {
     "duration": 0.018581,
     "end_time": "2023-04-01T04:55:56.641459",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.622878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The best way to understand the function above is by calling it. Let's take below data as an example. So the input to the `preprocess_layer` is of shape $(23, 543, 3)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c978c3a",
   "metadata": {
    "papermill": {
     "duration": 0.018525,
     "end_time": "2023-04-01T04:55:56.678845",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.660320",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This represents 23 Frames, 543 landmarks (face, hand, pose) & 3 coordinates ($X$, $Y$ & $Z$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d329165",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:56.718323Z",
     "iopub.status.busy": "2023-04-01T04:55:56.717944Z",
     "iopub.status.idle": "2023-04-01T04:55:56.798037Z",
     "shell.execute_reply": "2023-04-01T04:55:56.797011Z"
    },
    "papermill": {
     "duration": 0.102487,
     "end_time": "2023-04-01T04:55:56.800143",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.697656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 543, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# サンプルにparquetデータ一つからデータを取り出す\n",
    "sample = load_relevant_data_subset(train.path[0])\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de0da4b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:56.840337Z",
     "iopub.status.busy": "2023-04-01T04:55:56.839986Z",
     "iopub.status.idle": "2023-04-01T04:55:57.836643Z",
     "shell.execute_reply": "2023-04-01T04:55:57.835444Z"
    },
    "papermill": {
     "duration": 1.01956,
     "end_time": "2023-04-01T04:55:57.839283",
     "exception": false,
     "start_time": "2023-04-01T04:55:56.819723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([32, 92, 3]),\n",
       " <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       " array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 22., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        -1., -1., -1., -1., -1., -1.], dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取り出したサンプルデータに前処理をかける\n",
    "data, non_empty_frames_idxs = preprocess_layer(sample)\n",
    "data.shape, non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85509ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:57.880776Z",
     "iopub.status.busy": "2023-04-01T04:55:57.879731Z",
     "iopub.status.idle": "2023-04-01T04:55:57.884931Z",
     "shell.execute_reply": "2023-04-01T04:55:57.883935Z"
    },
    "papermill": {
     "duration": 0.027442,
     "end_time": "2023-04-01T04:55:57.887095",
     "exception": false,
     "start_time": "2023-04-01T04:55:57.859653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# free up RAM, delete variables as we go\n",
    "del data; del non_empty_frames_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4defc487",
   "metadata": {
    "papermill": {
     "duration": 0.018796,
     "end_time": "2023-04-01T04:55:57.924828",
     "exception": false,
     "start_time": "2023-04-01T04:55:57.906032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As can be seen above the output is of shape $(32, 92, 3)$, can you guess why? Take a minute to read the function above and try to guess why. It will help in your understanding of the code. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c3d50",
   "metadata": {
    "papermill": {
     "duration": 0.019312,
     "end_time": "2023-04-01T04:55:57.963946",
     "exception": false,
     "start_time": "2023-04-01T04:55:57.944634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the output 32 represents the interpolated frame size, 92 key landmarks that we keep instead of 543 and 3 coordinates - $X$, $Y$ and $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb7d942",
   "metadata": {
    "papermill": {
     "duration": 0.01885,
     "end_time": "2023-04-01T04:55:58.001931",
     "exception": false,
     "start_time": "2023-04-01T04:55:57.983081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What about when `N_FRAMES < cfg.INPUT_SIZE` is False? I leave that as an exercise for you. :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2afc04",
   "metadata": {
    "papermill": {
     "duration": 0.018853,
     "end_time": "2023-04-01T04:55:58.039854",
     "exception": false,
     "start_time": "2023-04-01T04:55:58.021001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "101a994e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:58.080389Z",
     "iopub.status.busy": "2023-04-01T04:55:58.080020Z",
     "iopub.status.idle": "2023-04-01T04:55:58.085034Z",
     "shell.execute_reply": "2023-04-01T04:55:58.084033Z"
    },
    "papermill": {
     "duration": 0.028193,
     "end_time": "2023-04-01T04:55:58.087183",
     "exception": false,
     "start_time": "2023-04-01T04:55:58.058990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LIPS_START = 0\n",
    "LEFT_HAND_START = LIPS_IDXS.size\n",
    "RIGHT_HAND_START = LEFT_HAND_START + LEFT_HAND_IDXS.size\n",
    "POSE_START = RIGHT_HAND_START + RIGHT_HAND_IDXS.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e51652b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:58.127259Z",
     "iopub.status.busy": "2023-04-01T04:55:58.126319Z",
     "iopub.status.idle": "2023-04-01T04:55:58.131568Z",
     "shell.execute_reply": "2023-04-01T04:55:58.130509Z"
    },
    "papermill": {
     "duration": 0.027721,
     "end_time": "2023-04-01T04:55:58.133697",
     "exception": false,
     "start_time": "2023-04-01T04:55:58.105976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(file_path):\n",
    "    data = load_relevant_data_subset(file_path)\n",
    "    data = preprocess_layer(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d566046d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:58.173522Z",
     "iopub.status.busy": "2023-04-01T04:55:58.173154Z",
     "iopub.status.idle": "2023-04-01T04:55:58.181269Z",
     "shell.execute_reply": "2023-04-01T04:55:58.180181Z"
    },
    "papermill": {
     "duration": 0.030459,
     "end_time": "2023-04-01T04:55:58.183362",
     "exception": false,
     "start_time": "2023-04-01T04:55:58.152903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# サンプルではなく全てのデータに対して行う\n",
    "def get_x_y():\n",
    "    # Create arrays to save data\n",
    "    X = np.zeros([N_SAMPLES, INPUT_SIZE, N_COLS, N_DIMS], dtype=np.float32)\n",
    "    y = np.zeros([N_SAMPLES], dtype=np.int32)\n",
    "    NON_EMPTY_FRAME_IDXS = np.full([N_SAMPLES, INPUT_SIZE], -1, dtype=np.float32)\n",
    "\n",
    "    for row_idx, (file_path, sign_ord) in enumerate(tqdm(train[['file_path', 'sign_ord']].values)):\n",
    "        if row_idx % 5000 == 0:\n",
    "            print(f'Generated {row_idx}/{N_SAMPLES}')\n",
    "\n",
    "        data, non_empty_frame_idxs = get_data(file_path)\n",
    "        X[row_idx] = data\n",
    "        y[row_idx] = sign_ord\n",
    "        NON_EMPTY_FRAME_IDXS[row_idx] = non_empty_frame_idxs\n",
    "        if np.isnan(data).sum() > 0: return data\n",
    "\n",
    "    # Save X/y\n",
    "    np.save('X.npy', X)\n",
    "    np.save('y.npy', y)\n",
    "    np.save('NON_EMPTY_FRAME_IDXS.npy', NON_EMPTY_FRAME_IDXS)\n",
    "    \n",
    "    return X, y, NON_EMPTY_FRAME_IDXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e553c93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:55:58.223878Z",
     "iopub.status.busy": "2023-04-01T04:55:58.223499Z",
     "iopub.status.idle": "2023-04-01T04:56:20.245437Z",
     "shell.execute_reply": "2023-04-01T04:56:20.244247Z"
    },
    "papermill": {
     "duration": 22.045251,
     "end_time": "2023-04-01T04:56:20.248298",
     "exception": false,
     "start_time": "2023-04-01T04:55:58.203047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cfg.PREPROCESS_DATA:\n",
    "    X, y, NON_EMPTY_FRAME_IDXS = get_x_y()\n",
    "else:\n",
    "    X = np.load('/kaggle/input/gislr-dataset-public/X.npy')\n",
    "    y = np.load('/kaggle/input/gislr-dataset-public/y.npy')\n",
    "    NON_EMPTY_FRAME_IDXS = np.load('/kaggle/input/gislr-dataset-public/NON_EMPTY_FRAME_IDXS.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc23fcd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:20.289942Z",
     "iopub.status.busy": "2023-04-01T04:56:20.289558Z",
     "iopub.status.idle": "2023-04-01T04:56:20.296808Z",
     "shell.execute_reply": "2023-04-01T04:56:20.295676Z"
    },
    "papermill": {
     "duration": 0.031487,
     "end_time": "2023-04-01T04:56:20.300340",
     "exception": false,
     "start_time": "2023-04-01T04:56:20.268853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((94477, 32, 92, 3), (94477,), (94477, 32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, NON_EMPTY_FRAME_IDXS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4f1c2",
   "metadata": {
    "papermill": {
     "duration": 0.019317,
     "end_time": "2023-04-01T04:56:20.338701",
     "exception": false,
     "start_time": "2023-04-01T04:56:20.319384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Statistics - Lips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e13e731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:20.379562Z",
     "iopub.status.busy": "2023-04-01T04:56:20.378572Z",
     "iopub.status.idle": "2023-04-01T04:56:27.995626Z",
     "shell.execute_reply": "2023-04-01T04:56:27.994548Z"
    },
    "papermill": {
     "duration": 7.640427,
     "end_time": "2023-04-01T04:56:27.998152",
     "exception": false,
     "start_time": "2023-04-01T04:56:20.357725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4978464b71346b0b5fa7855a11dfcfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LIPS\n",
    "LIPS_MEAN_X  = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_MEAN_Y  = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_STD_X   = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "LIPS_STD_Y   = np.zeros([LIPS_IDXS.size], dtype=np.float32)\n",
    "\n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,LIPS_IDXS], [2,3,0,1]).reshape([LIPS_IDXS.size, cfg.N_DIMS, -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            LIPS_MEAN_X[col] = v.mean()\n",
    "            LIPS_STD_X[col] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            LIPS_MEAN_Y[col] = v.mean()\n",
    "            LIPS_STD_Y[col] = v.std()\n",
    "        \n",
    "LIPS_MEAN = np.array([LIPS_MEAN_X, LIPS_MEAN_Y]).T\n",
    "LIPS_STD = np.array([LIPS_STD_X, LIPS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d889044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:28.039393Z",
     "iopub.status.busy": "2023-04-01T04:56:28.038684Z",
     "iopub.status.idle": "2023-04-01T04:56:28.046969Z",
     "shell.execute_reply": "2023-04-01T04:56:28.045799Z"
    },
    "papermill": {
     "duration": 0.031132,
     "end_time": "2023-04-01T04:56:28.049296",
     "exception": false,
     "start_time": "2023-04-01T04:56:28.018164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41621253, 0.47286358],\n",
       "       [0.41961774, 0.46850088],\n",
       "       [0.4259194 , 0.46398672],\n",
       "       [0.4352784 , 0.45886287],\n",
       "       [0.45009747, 0.4540205 ],\n",
       "       [0.46598187, 0.45563185],\n",
       "       [0.48191077, 0.4531696 ],\n",
       "       [0.49807605, 0.45723534],\n",
       "       [0.50854623, 0.46182665],\n",
       "       [0.51606447, 0.46596456],\n",
       "       [0.5205674 , 0.47018802],\n",
       "       [0.42088684, 0.47698584],\n",
       "       [0.42751804, 0.48136103],\n",
       "       [0.43815812, 0.48646846],\n",
       "       [0.45204934, 0.4899064 ],\n",
       "       [0.46841824, 0.4906653 ],\n",
       "       [0.48489097, 0.48926488],\n",
       "       [0.49900448, 0.48520103],\n",
       "       [0.5095267 , 0.4795264 ],\n",
       "       [0.5161358 , 0.47465026],\n",
       "       [0.42128628, 0.47240794],\n",
       "       [0.42840737, 0.4706431 ],\n",
       "       [0.43501914, 0.46912196],\n",
       "       [0.4436666 , 0.4678137 ],\n",
       "       [0.45443463, 0.46722496],\n",
       "       [0.4669518 , 0.46721676],\n",
       "       [0.4797852 , 0.4665954 ],\n",
       "       [0.49100533, 0.46661043],\n",
       "       [0.50035226, 0.46742183],\n",
       "       [0.50782615, 0.46858737],\n",
       "       [0.4286374 , 0.47284102],\n",
       "       [0.43516156, 0.47301847],\n",
       "       [0.44386455, 0.47317308],\n",
       "       [0.45467642, 0.47352698],\n",
       "       [0.4674016 , 0.47379026],\n",
       "       [0.48033133, 0.47293735],\n",
       "       [0.49148002, 0.4720236 ],\n",
       "       [0.50069   , 0.4713964 ],\n",
       "       [0.507654  , 0.47086492],\n",
       "       [0.51544726, 0.46998656]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIPS_MEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706eda66",
   "metadata": {
    "papermill": {
     "duration": 0.020293,
     "end_time": "2023-04-01T04:56:28.090331",
     "exception": false,
     "start_time": "2023-04-01T04:56:28.070038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Statistics - Hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "334540b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:28.131303Z",
     "iopub.status.busy": "2023-04-01T04:56:28.130884Z",
     "iopub.status.idle": "2023-04-01T04:56:36.516841Z",
     "shell.execute_reply": "2023-04-01T04:56:36.515681Z"
    },
    "papermill": {
     "duration": 8.411061,
     "end_time": "2023-04-01T04:56:36.520821",
     "exception": false,
     "start_time": "2023-04-01T04:56:28.109760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2852084f0bbe44d4ba87f147ee16e6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LEFT HAND\n",
    "LEFT_HANDS_MEAN_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_MEAN_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_STD_X = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "LEFT_HANDS_STD_Y = np.zeros([LEFT_HAND_IDXS.size], dtype=np.float32)\n",
    "# RIGHT HAND\n",
    "RIGHT_HANDS_MEAN_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_MEAN_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_STD_X = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "RIGHT_HANDS_STD_Y = np.zeros([RIGHT_HAND_IDXS.size], dtype=np.float32)\n",
    "\n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,HAND_IDXS], [2,3,0,1]).reshape([HAND_IDXS.size, cfg.N_DIMS, -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "                LEFT_HANDS_MEAN_X[col] = v.mean()\n",
    "                LEFT_HANDS_STD_X[col] = v.std()\n",
    "            else:\n",
    "                RIGHT_HANDS_MEAN_X[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "                RIGHT_HANDS_STD_X[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            if col < RIGHT_HAND_IDXS.size: # LEFT HAND\n",
    "                LEFT_HANDS_MEAN_Y[col] = v.mean()\n",
    "                LEFT_HANDS_STD_Y[col] = v.std()\n",
    "            else: # RIGHT HAND\n",
    "                RIGHT_HANDS_MEAN_Y[col - LEFT_HAND_IDXS.size] = v.mean()\n",
    "                RIGHT_HANDS_STD_Y[col - LEFT_HAND_IDXS.size] = v.std()\n",
    "        \n",
    "LEFT_HANDS_MEAN = np.array([LEFT_HANDS_MEAN_X, LEFT_HANDS_MEAN_Y]).T\n",
    "LEFT_HANDS_STD = np.array([LEFT_HANDS_STD_X, LEFT_HANDS_STD_Y]).T\n",
    "RIGHT_HANDS_MEAN = np.array([RIGHT_HANDS_MEAN_X, RIGHT_HANDS_MEAN_Y]).T\n",
    "RIGHT_HANDS_STD = np.array([RIGHT_HANDS_STD_X, RIGHT_HANDS_STD_Y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a74ab14",
   "metadata": {
    "papermill": {
     "duration": 0.019475,
     "end_time": "2023-04-01T04:56:36.560488",
     "exception": false,
     "start_time": "2023-04-01T04:56:36.541013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Statistics - Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b39d028d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:36.602045Z",
     "iopub.status.busy": "2023-04-01T04:56:36.601022Z",
     "iopub.status.idle": "2023-04-01T04:56:39.061681Z",
     "shell.execute_reply": "2023-04-01T04:56:39.060539Z"
    },
    "papermill": {
     "duration": 2.483779,
     "end_time": "2023-04-01T04:56:39.064078",
     "exception": false,
     "start_time": "2023-04-01T04:56:36.580299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11eaf751e54d4e8e879c8b7258b1ef88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# POSE\n",
    "POSE_MEAN_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_MEAN_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_STD_X = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "POSE_STD_Y = np.zeros([POSE_IDXS.size], dtype=np.float32)\n",
    "\n",
    "for col, ll in enumerate(tqdm( np.transpose(X[:,:,POSE_IDXS], [2,3,0,1]).reshape([POSE_IDXS.size, cfg.N_DIMS, -1]) )):\n",
    "    for dim, l in enumerate(ll):\n",
    "        v = l[np.nonzero(l)]\n",
    "        if dim == 0: # X\n",
    "            POSE_MEAN_X[col] = v.mean()\n",
    "            POSE_STD_X[col] = v.std()\n",
    "        if dim == 1: # Y\n",
    "            POSE_MEAN_Y[col] = v.mean()\n",
    "            POSE_STD_Y[col] = v.std()\n",
    "        \n",
    "POSE_MEAN = np.array([POSE_MEAN_X, POSE_MEAN_Y]).T\n",
    "POSE_STD = np.array([POSE_STD_X, POSE_STD_Y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3a955",
   "metadata": {
    "papermill": {
     "duration": 0.020279,
     "end_time": "2023-04-01T04:56:39.105065",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.084786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b99bc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.146766Z",
     "iopub.status.busy": "2023-04-01T04:56:39.146090Z",
     "iopub.status.idle": "2023-04-01T04:56:39.155148Z",
     "shell.execute_reply": "2023-04-01T04:56:39.154072Z"
    },
    "papermill": {
     "duration": 0.032611,
     "end_time": "2023-04-01T04:56:39.157324",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.124713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom sampler to get a batch containing N times all signs\n",
    "def get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n=cfg.BATCH_ALL_SIGNS_N):\n",
    "    # Arrays to store batch in\n",
    "    X_batch = np.zeros([cfg.NUM_CLASSES*n, cfg.INPUT_SIZE, N_COLS, cfg.N_DIMS], dtype=np.float32)\n",
    "    y_batch = np.arange(0, cfg.NUM_CLASSES, step=1/n, dtype=np.float32).astype(np.int64)\n",
    "    non_empty_frame_idxs_batch = np.zeros([cfg.NUM_CLASSES*n, cfg.INPUT_SIZE], dtype=np.float32)\n",
    "    \n",
    "    # Dictionary mapping ordinally encoded sign to corresponding sample indices\n",
    "    CLASS2IDXS = {}\n",
    "    for i in range(cfg.NUM_CLASSES):\n",
    "        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)\n",
    "            \n",
    "    while True:\n",
    "        # Fill batch arrays\n",
    "        for i in range(cfg.NUM_CLASSES):\n",
    "            idxs = np.random.choice(CLASS2IDXS[i], n)\n",
    "            X_batch[i*n:(i+1)*n] = X[idxs]\n",
    "            non_empty_frame_idxs_batch[i*n:(i+1)*n] = NON_EMPTY_FRAME_IDXS[idxs]\n",
    "        \n",
    "        yield { 'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70316917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.199545Z",
     "iopub.status.busy": "2023-04-01T04:56:39.198497Z",
     "iopub.status.idle": "2023-04-01T04:56:39.266736Z",
     "shell.execute_reply": "2023-04-01T04:56:39.265534Z"
    },
    "papermill": {
     "duration": 0.092003,
     "end_time": "2023-04-01T04:56:39.269394",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.177391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['frames', 'non_empty_frame_idxs']), (1000, 32, 92, 3))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dataset = get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS)\n",
    "X_batch, y_batch = next(dummy_dataset)\n",
    "X_batch.keys(), X_batch['frames'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23a564",
   "metadata": {
    "papermill": {
     "duration": 0.019679,
     "end_time": "2023-04-01T04:56:39.309125",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.289446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e7d723a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.350854Z",
     "iopub.status.busy": "2023-04-01T04:56:39.350113Z",
     "iopub.status.idle": "2023-04-01T04:56:39.358227Z",
     "shell.execute_reply": "2023-04-01T04:56:39.357243Z"
    },
    "papermill": {
     "duration": 0.031749,
     "end_time": "2023-04-01T04:56:39.360579",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.328830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Epsilon value for layer normalisation\n",
    "LAYER_NORM_EPS = 1e-6\n",
    "\n",
    "# Dense layer units for landmarks\n",
    "LIPS_UNITS = 384\n",
    "HANDS_UNITS = 384\n",
    "POSE_UNITS = 384\n",
    "# final embedding and transformer embedding size\n",
    "UNITS = 384\n",
    "\n",
    "# Transformer\n",
    "NUM_BLOCKS = 2\n",
    "MLP_RATIO = 2\n",
    "\n",
    "# Dropout\n",
    "EMBEDDING_DROPOUT = 0.00\n",
    "MLP_DROPOUT_RATIO = 0.30\n",
    "CLASSIFIER_DROPOUT_RATIO = 0.10\n",
    "\n",
    "# Initiailizers\n",
    "INIT_HE_UNIFORM = tf.keras.initializers.he_uniform\n",
    "INIT_GLOROT_UNIFORM = tf.keras.initializers.glorot_uniform\n",
    "INIT_ZEROS = tf.keras.initializers.constant(0.0)\n",
    "# Activations\n",
    "GELU = tf.keras.activations.gelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c5db6",
   "metadata": {
    "papermill": {
     "duration": 0.019861,
     "end_time": "2023-04-01T04:56:39.401159",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.381298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Transformer\n",
    "\n",
    "Need to implement transformer from scratch as TFLite does not support the native TF implementation of MultiHeadAttention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5df1448",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.443315Z",
     "iopub.status.busy": "2023-04-01T04:56:39.442359Z",
     "iopub.status.idle": "2023-04-01T04:56:39.454299Z",
     "shell.execute_reply": "2023-04-01T04:56:39.453340Z"
    },
    "papermill": {
     "duration": 0.035413,
     "end_time": "2023-04-01T04:56:39.456549",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.421136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on: https://stackoverflow.com/questions/67342988/verifying-the-implementation-of-multihead-attention-in-transformer\n",
    "# replaced softmax with softmax layer to support masked softmax\n",
    "def scaled_dot_product(q,k,v, softmax, attention_mask):\n",
    "    #calculates Q . K(transpose)\n",
    "    qkt = tf.matmul(q,k,transpose_b=True)\n",
    "    #caculates scaling factor\n",
    "    dk = tf.math.sqrt(tf.cast(q.shape[-1],dtype=tf.float32))\n",
    "    scaled_qkt = qkt/dk\n",
    "    softmax = softmax(scaled_qkt, mask=attention_mask)\n",
    "    \n",
    "    z = tf.matmul(softmax,v)\n",
    "    #shape: (m,Tx,depth), same shape as q,k,v\n",
    "    return z\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_of_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_of_heads = num_of_heads\n",
    "        self.depth = d_model//num_of_heads\n",
    "        self.wq = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wk = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wv = [tf.keras.layers.Dense(self.depth) for i in range(num_of_heads)]\n",
    "        self.wo = tf.keras.layers.Dense(d_model)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self,x, attention_mask):\n",
    "        \n",
    "        multi_attn = []\n",
    "        for i in range(self.num_of_heads):\n",
    "            Q = self.wq[i](x)\n",
    "            K = self.wk[i](x)\n",
    "            V = self.wv[i](x)\n",
    "            multi_attn.append(scaled_dot_product(Q,K,V, self.softmax, attention_mask))\n",
    "            \n",
    "        multi_head = tf.concat(multi_attn,axis=-1)\n",
    "        multi_head_attention = self.wo(multi_head)\n",
    "        return multi_head_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcb646ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.498780Z",
     "iopub.status.busy": "2023-04-01T04:56:39.497670Z",
     "iopub.status.idle": "2023-04-01T04:56:39.508439Z",
     "shell.execute_reply": "2023-04-01T04:56:39.507514Z"
    },
    "papermill": {
     "duration": 0.034133,
     "end_time": "2023-04-01T04:56:39.510710",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.476577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Transformer, self).__init__(name='transformer')\n",
    "        self.num_blocks = num_blocks\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.ln_1s = []\n",
    "        self.mhas = []\n",
    "        self.ln_2s = []\n",
    "        self.mlps = []\n",
    "        # Make Transformer Blocks\n",
    "        for i in range(self.num_blocks):\n",
    "            # First Layer Normalisation\n",
    "            self.ln_1s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Head Attention\n",
    "            self.mhas.append(MultiHeadAttention(UNITS, 8))\n",
    "            # Second Layer Normalisation\n",
    "            self.ln_2s.append(tf.keras.layers.LayerNormalization(epsilon=LAYER_NORM_EPS))\n",
    "            # Multi Layer Perception\n",
    "            self.mlps.append(tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(UNITS * MLP_RATIO, activation=GELU, kernel_initializer=INIT_GLOROT_UNIFORM),\n",
    "                tf.keras.layers.Dropout(MLP_DROPOUT_RATIO),\n",
    "                tf.keras.layers.Dense(UNITS, kernel_initializer=INIT_HE_UNIFORM),\n",
    "            ]))\n",
    "        \n",
    "    def call(self, x, attention_mask):\n",
    "        # Iterate input over transformer blocks\n",
    "        for ln_1, mha, ln_2, mlp in zip(self.ln_1s, self.mhas, self.ln_2s, self.mlps):\n",
    "            x1 = ln_1(x)\n",
    "            attention_output = mha(x1, attention_mask)\n",
    "            x2 = x1 + attention_output\n",
    "            x3 = ln_2(x2)\n",
    "            x3 = mlp(x3)\n",
    "            x = x3 + x2\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9be6fc",
   "metadata": {
    "papermill": {
     "duration": 0.019814,
     "end_time": "2023-04-01T04:56:39.550870",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.531056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Landmark Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67c5e01a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.592941Z",
     "iopub.status.busy": "2023-04-01T04:56:39.592581Z",
     "iopub.status.idle": "2023-04-01T04:56:39.601855Z",
     "shell.execute_reply": "2023-04-01T04:56:39.600410Z"
    },
    "papermill": {
     "duration": 0.032893,
     "end_time": "2023-04-01T04:56:39.604199",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.571306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LandmarkEmbedding(tf.keras.Model):\n",
    "    def __init__(self, units, name):\n",
    "        super(LandmarkEmbedding, self).__init__(name=f'{name}_embedding')\n",
    "        self.units = units\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Embedding for missing landmark in frame, initizlied with zeros\n",
    "        self.empty_embedding = self.add_weight(\n",
    "            name=f'{self.name}_empty_embedding',\n",
    "            shape=[self.units],\n",
    "            initializer=INIT_ZEROS,\n",
    "        )\n",
    "        # Embedding\n",
    "        self.dense = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
    "            tf.keras.layers.Dense(self.units, name=f'{self.name}_dense_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name=f'{self.name}_dense')\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.where(\n",
    "                # Checks whether landmark is missing in frame\n",
    "                tf.reduce_sum(x, axis=2, keepdims=True) == 0,\n",
    "                # If so, the empty embedding is used\n",
    "                self.empty_embedding,\n",
    "                # Otherwise the landmark data is embedded\n",
    "                self.dense(x),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd097f5",
   "metadata": {
    "papermill": {
     "duration": 0.01966,
     "end_time": "2023-04-01T04:56:39.644339",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.624679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4ef451e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.686511Z",
     "iopub.status.busy": "2023-04-01T04:56:39.685586Z",
     "iopub.status.idle": "2023-04-01T04:56:39.700231Z",
     "shell.execute_reply": "2023-04-01T04:56:39.699019Z"
    },
    "papermill": {
     "duration": 0.038466,
     "end_time": "2023-04-01T04:56:39.702601",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.664135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomEmbedding(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        \n",
    "    def get_diffs(self, l):\n",
    "        S = l.shape[2]\n",
    "        other = tf.expand_dims(l, 3)\n",
    "        other = tf.repeat(other, S, axis=3)\n",
    "        other = tf.transpose(other, [0,1,3,2])\n",
    "        diffs = tf.expand_dims(l, 3) - other\n",
    "        diffs = tf.reshape(diffs, [-1, cfg.INPUT_SIZE, S*S])\n",
    "        return diffs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Positional Embedding, initialized with zeros\n",
    "        self.positional_embedding = tf.keras.layers.Embedding(cfg.INPUT_SIZE+1, UNITS, embeddings_initializer=INIT_ZEROS)\n",
    "        # Embedding layer for Landmarks\n",
    "        self.lips_embedding = LandmarkEmbedding(LIPS_UNITS, 'lips')\n",
    "        self.left_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'left_hand')\n",
    "        self.right_hand_embedding = LandmarkEmbedding(HANDS_UNITS, 'right_hand')\n",
    "        self.pose_embedding = LandmarkEmbedding(POSE_UNITS, 'pose')\n",
    "        # Landmark Weights\n",
    "        self.landmark_weights = tf.Variable(tf.zeros([4], dtype=tf.float32), name='landmark_weights')\n",
    "        # Fully Connected Layers for combined landmarks\n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_1', use_bias=False, kernel_initializer=INIT_GLOROT_UNIFORM, activation=GELU),\n",
    "            tf.keras.layers.Dense(UNITS, name='fully_connected_2', use_bias=False, kernel_initializer=INIT_HE_UNIFORM),\n",
    "        ], name='fc')\n",
    "\n",
    "\n",
    "    def call(self, lips0, left_hand0, right_hand0, pose0, non_empty_frame_idxs, training=False):\n",
    "        # Lips\n",
    "        lips_embedding = self.lips_embedding(lips0)\n",
    "        # Left Hand\n",
    "        left_hand_embedding = self.left_hand_embedding(left_hand0)\n",
    "        # Right Hand\n",
    "        right_hand_embedding = self.right_hand_embedding(right_hand0)\n",
    "        # Pose\n",
    "        pose_embedding = self.pose_embedding(pose0)\n",
    "        # Merge Embeddings of all landmarks with mean pooling\n",
    "        x = tf.stack((lips_embedding, left_hand_embedding, right_hand_embedding, pose_embedding), axis=3)\n",
    "        # Merge Landmarks with trainable attention weights\n",
    "        x = x * tf.nn.softmax(self.landmark_weights)\n",
    "        x = tf.reduce_sum(x, axis=3)\n",
    "        # Fully Connected Layers\n",
    "        x = self.fc(x)\n",
    "        # Add Positional Embedding\n",
    "        normalised_non_empty_frame_idxs = tf.where(\n",
    "            tf.math.equal(non_empty_frame_idxs, -1.0),\n",
    "            cfg.INPUT_SIZE,\n",
    "            tf.cast(\n",
    "                non_empty_frame_idxs / tf.reduce_max(non_empty_frame_idxs, axis=1, keepdims=True) * cfg.INPUT_SIZE,\n",
    "                tf.int32,\n",
    "            ),\n",
    "        )\n",
    "        x = x + self.positional_embedding(normalised_non_empty_frame_idxs)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e43121b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.745001Z",
     "iopub.status.busy": "2023-04-01T04:56:39.743912Z",
     "iopub.status.idle": "2023-04-01T04:56:39.752266Z",
     "shell.execute_reply": "2023-04-01T04:56:39.748970Z"
    },
    "papermill": {
     "duration": 0.038205,
     "end_time": "2023-04-01T04:56:39.761071",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.722866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1270be6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.838091Z",
     "iopub.status.busy": "2023-04-01T04:56:39.837585Z",
     "iopub.status.idle": "2023-04-01T04:56:39.861838Z",
     "shell.execute_reply": "2023-04-01T04:56:39.860757Z"
    },
    "papermill": {
     "duration": 0.068362,
     "end_time": "2023-04-01T04:56:39.864930",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.796568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    # Inputs\n",
    "    frames = tf.keras.layers.Input([cfg.INPUT_SIZE, N_COLS, cfg.N_DIMS], dtype=tf.float32, name='frames')\n",
    "    non_empty_frame_idxs = tf.keras.layers.Input([cfg.INPUT_SIZE], dtype=tf.float32, name='non_empty_frame_idxs')\n",
    "    # Padding Mask\n",
    "    mask = tf.cast(tf.math.not_equal(non_empty_frame_idxs, -1), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=2)\n",
    "    \n",
    "    x = frames\n",
    "    x = tf.slice(x, [0,0,0,0], [-1,cfg.INPUT_SIZE, N_COLS, 2])\n",
    "    # LIPS\n",
    "    lips = tf.slice(x, [0,0,LIPS_START,0], [-1,cfg.INPUT_SIZE, 40, 2])\n",
    "    lips = tf.where(\n",
    "            tf.math.equal(lips, 0.0),\n",
    "            0.0,\n",
    "            (lips - LIPS_MEAN) / LIPS_STD,\n",
    "        )\n",
    "    lips = tf.reshape(lips, [-1, cfg.INPUT_SIZE, 40*2])\n",
    "    # LEFT HAND\n",
    "    left_hand = tf.slice(x, [0,0,40,0], [-1,cfg.INPUT_SIZE, 21, 2])\n",
    "    left_hand = tf.where(\n",
    "            tf.math.equal(left_hand, 0.0),\n",
    "            0.0,\n",
    "            (left_hand - LEFT_HANDS_MEAN) / LEFT_HANDS_STD,\n",
    "        )\n",
    "    left_hand = tf.reshape(left_hand, [-1, cfg.INPUT_SIZE, 21*2])\n",
    "    # RIGHT HAND\n",
    "    right_hand = tf.slice(x, [0,0,61,0], [-1,cfg.INPUT_SIZE, 21, 2])\n",
    "    right_hand = tf.where(\n",
    "            tf.math.equal(right_hand, 0.0),\n",
    "            0.0,\n",
    "            (right_hand - RIGHT_HANDS_MEAN) / RIGHT_HANDS_STD,\n",
    "        )\n",
    "    right_hand = tf.reshape(right_hand, [-1, cfg.INPUT_SIZE, 21*2])\n",
    "    # POSE\n",
    "    pose = tf.slice(x, [0,0,82,0], [-1,cfg.INPUT_SIZE, 10, 2])\n",
    "    pose = tf.where(\n",
    "            tf.math.equal(pose, 0.0),\n",
    "            0.0,\n",
    "            (pose - POSE_MEAN) / POSE_STD,\n",
    "        )\n",
    "    pose = tf.reshape(pose, [-1, cfg.INPUT_SIZE, 10*2])\n",
    "    x = lips, left_hand, right_hand, pose\n",
    "    x = CustomEmbedding()(lips, left_hand, right_hand, pose, non_empty_frame_idxs)\n",
    "    # Encoder Transformer Blocks\n",
    "    x = Transformer(NUM_BLOCKS)(x, mask)\n",
    "    # Pooling\n",
    "    x = tf.reduce_sum(x * mask, axis=1) / tf.reduce_sum(mask, axis=1)\n",
    "    # Classification Layer\n",
    "    x = tf.keras.layers.Dense(cfg.NUM_CLASSES, activation=tf.keras.activations.softmax, kernel_initializer=INIT_GLOROT_UNIFORM)(x)\n",
    "    outputs = x\n",
    "    \n",
    "    # Create Tensorflow Model\n",
    "    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)\n",
    "    \n",
    "    # Simple Categorical Crossentropy Loss\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    \n",
    "    # Adam Optimizer with weight decay\n",
    "    optimizer = tfa.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5, clipnorm=1.0)\n",
    "    \n",
    "    lr_metric = get_lr_metric(optimizer)\n",
    "    metrics = [\"acc\",lr_metric]\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1beefc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:39.926386Z",
     "iopub.status.busy": "2023-04-01T04:56:39.925797Z",
     "iopub.status.idle": "2023-04-01T04:56:42.842186Z",
     "shell.execute_reply": "2023-04-01T04:56:42.840970Z"
    },
    "papermill": {
     "duration": 2.949926,
     "end_time": "2023-04-01T04:56:42.844883",
     "exception": false,
     "start_time": "2023-04-01T04:56:39.894957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b23e005",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:42.886540Z",
     "iopub.status.busy": "2023-04-01T04:56:42.885454Z",
     "iopub.status.idle": "2023-04-01T04:56:42.992332Z",
     "shell.execute_reply": "2023-04-01T04:56:42.991546Z"
    },
    "papermill": {
     "duration": 0.178717,
     "end_time": "2023-04-01T04:56:43.043289",
     "exception": false,
     "start_time": "2023-04-01T04:56:42.864572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " frames (InputLayer)            [(None, 32, 92, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)          (None, 32, 92, 2)    0           ['frames[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)        (None, 32, 40, 2)    0           ['tf.slice[0][0]']               \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)        (None, 32, 21, 2)    0           ['tf.slice[0][0]']               \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)        (None, 32, 21, 2)    0           ['tf.slice[0][0]']               \n",
      "                                                                                                  \n",
      " tf.slice_4 (TFOpLambda)        (None, 32, 10, 2)    0           ['tf.slice[0][0]']               \n",
      "                                                                                                  \n",
      " tf.math.subtract (TFOpLambda)  (None, 32, 40, 2)    0           ['tf.slice_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.subtract_1 (TFOpLambda  (None, 32, 21, 2)   0           ['tf.slice_2[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 32, 21, 2)   0           ['tf.slice_3[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 32, 10, 2)   0           ['tf.slice_4[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.equal (TFOpLambda)     (None, 32, 40, 2)    0           ['tf.slice_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambda)   (None, 32, 40, 2)    0           ['tf.math.subtract[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.equal_1 (TFOpLambda)   (None, 32, 21, 2)    0           ['tf.slice_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLambda)  (None, 32, 21, 2)   0           ['tf.math.subtract_1[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.equal_2 (TFOpLambda)   (None, 32, 21, 2)    0           ['tf.slice_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLambda)  (None, 32, 21, 2)   0           ['tf.math.subtract_2[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.equal_3 (TFOpLambda)   (None, 32, 10, 2)    0           ['tf.slice_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLambda)  (None, 32, 10, 2)   0           ['tf.math.subtract_3[0][0]']     \n",
      "                                                                                                  \n",
      " non_empty_frame_idxs (InputLay  [(None, 32)]        0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " tf.where (TFOpLambda)          (None, 32, 40, 2)    0           ['tf.math.equal[0][0]',          \n",
      "                                                                  'tf.math.truediv[0][0]']        \n",
      "                                                                                                  \n",
      " tf.where_1 (TFOpLambda)        (None, 32, 21, 2)    0           ['tf.math.equal_1[0][0]',        \n",
      "                                                                  'tf.math.truediv_1[0][0]']      \n",
      "                                                                                                  \n",
      " tf.where_2 (TFOpLambda)        (None, 32, 21, 2)    0           ['tf.math.equal_2[0][0]',        \n",
      "                                                                  'tf.math.truediv_2[0][0]']      \n",
      "                                                                                                  \n",
      " tf.where_3 (TFOpLambda)        (None, 32, 10, 2)    0           ['tf.math.equal_3[0][0]',        \n",
      "                                                                  'tf.math.truediv_3[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.not_equal (TFOpLambda)  (None, 32)          0           ['non_empty_frame_idxs[0][0]']   \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 32, 80)       0           ['tf.where[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 32, 42)       0           ['tf.where_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 32, 42)       0           ['tf.where_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 32, 20)       0           ['tf.where_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)           (None, 32)           0           ['tf.math.not_equal[0][0]']      \n",
      "                                                                                                  \n",
      " custom_embedding (CustomEmbedd  (None, 32, 384)     969604      ['tf.reshape[0][0]',             \n",
      " ing)                                                             'tf.reshape_1[0][0]',           \n",
      "                                                                  'tf.reshape_2[0][0]',           \n",
      "                                                                  'tf.reshape_3[0][0]',           \n",
      "                                                                  'non_empty_frame_idxs[0][0]']   \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 32, 1)        0           ['tf.cast[0][0]']                \n",
      "                                                                                                  \n",
      " transformer (Transformer)      (None, 32, 384)      2367744     ['custom_embedding[0][0]',       \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 32, 384)      0           ['transformer[0][0]',            \n",
      "                                                                  'tf.expand_dims[0][0]']         \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 384)         0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None, 1)           0           ['tf.expand_dims[0][0]']         \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.truediv_4 (TFOpLambda)  (None, 384)         0           ['tf.math.reduce_sum[0][0]',     \n",
      "                                                                  'tf.math.reduce_sum_1[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 250)          96250       ['tf.math.truediv_4[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,433,598\n",
      "Trainable params: 3,433,598\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9d21b8",
   "metadata": {
    "papermill": {
     "duration": 0.024741,
     "end_time": "2023-04-01T04:56:43.093273",
     "exception": false,
     "start_time": "2023-04-01T04:56:43.068532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8046214",
   "metadata": {
    "papermill": {
     "duration": 0.025612,
     "end_time": "2023-04-01T04:56:43.144663",
     "exception": false,
     "start_time": "2023-04-01T04:56:43.119051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Weight Decay Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fa0230",
   "metadata": {
    "papermill": {
     "duration": 0.025432,
     "end_time": "2023-04-01T04:56:43.196551",
     "exception": false,
     "start_time": "2023-04-01T04:56:43.171119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Performance Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d23e3",
   "metadata": {
    "papermill": {
     "duration": 0.024495,
     "end_time": "2023-04-01T04:56:43.308518",
     "exception": false,
     "start_time": "2023-04-01T04:56:43.284023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc8ddefe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:43.360612Z",
     "iopub.status.busy": "2023-04-01T04:56:43.359465Z",
     "iopub.status.idle": "2023-04-01T04:56:45.251490Z",
     "shell.execute_reply": "2023-04-01T04:56:45.250378Z"
    },
    "papermill": {
     "duration": 1.920971,
     "end_time": "2023-04-01T04:56:45.254328",
     "exception": false,
     "start_time": "2023-04-01T04:56:43.333357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = X[train_idxs]\n",
    "X_val = X[val_idxs]\n",
    "NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS[train_idxs]\n",
    "NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS[val_idxs]\n",
    "y_train = y[train_idxs]\n",
    "y_val = y[val_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e3c6268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:45.308226Z",
     "iopub.status.busy": "2023-04-01T04:56:45.307840Z",
     "iopub.status.idle": "2023-04-01T04:56:56.006486Z",
     "shell.execute_reply": "2023-04-01T04:56:56.005407Z"
    },
    "papermill": {
     "duration": 10.727266,
     "end_time": "2023-04-01T04:56:56.008672",
     "exception": false,
     "start_time": "2023-04-01T04:56:45.281406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 - 9s - 9s/epoch - 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model weights and do sanity c\n",
    "model.load_weights(\"/kaggle/input/models-pm/transformer_baseline.h5\")\n",
    "y_val_pred = model.predict({ 'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, verbose=2).argmax(axis=1)\n",
    "np.mean(y_val == y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd4a7f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:56.060551Z",
     "iopub.status.busy": "2023-04-01T04:56:56.060155Z",
     "iopub.status.idle": "2023-04-01T04:56:56.103265Z",
     "shell.execute_reply": "2023-04-01T04:56:56.102208Z"
    },
    "papermill": {
     "duration": 0.071653,
     "end_time": "2023-04-01T04:56:56.105582",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.033929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete variables as we go to free up RAM\n",
    "del X; del y; del X_train; del X_val; del y_train; del y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780c2eb9",
   "metadata": {
    "papermill": {
     "duration": 0.024707,
     "end_time": "2023-04-01T04:56:56.155798",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.131091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Landmark Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc037c5d",
   "metadata": {
    "papermill": {
     "duration": 0.024853,
     "end_time": "2023-04-01T04:56:56.206073",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.181220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By checking attention weights as from the original notebook, we can check that the left hand and right hand signals are the most important. This makes sense right? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d56180b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:56.258721Z",
     "iopub.status.busy": "2023-04-01T04:56:56.257437Z",
     "iopub.status.idle": "2023-04-01T04:56:56.271064Z",
     "shell.execute_reply": "2023-04-01T04:56:56.269700Z"
    },
    "papermill": {
     "duration": 0.043215,
     "end_time": "2023-04-01T04:56:56.274210",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.230995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lips_embedding weight: 21.5%\n",
      "left_hand_embedding weight: 29.2%\n",
      "right_hand_embedding weight: 30.5%\n",
      "pose_embedding weight: 18.7%\n"
     ]
    }
   ],
   "source": [
    "# Landmark Weights\n",
    "weights = scipy.special.softmax(model.get_layer('custom_embedding').weights[15])\n",
    "landmarks = ['lips_embedding', 'left_hand_embedding', 'right_hand_embedding', 'pose_embedding']\n",
    "\n",
    "# Learned attention weights, initialized at uniform 25%\n",
    "for w, lm in zip(weights, landmarks):\n",
    "    print(f'{lm} weight: {(w*100):.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b497029",
   "metadata": {
    "papermill": {
     "duration": 0.025649,
     "end_time": "2023-04-01T04:56:56.328387",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.302738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have the first model ready, let's also work on the second model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb6398e",
   "metadata": {
    "papermill": {
     "duration": 0.024923,
     "end_time": "2023-04-01T04:56:56.378947",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.354024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model - 2 (Linear layer, BN, ReLU)\n",
    "> From https://www.kaggle.com/code/roberthatch/gislr-lb-0-63-on-the-shoulders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dfa5d",
   "metadata": {
    "papermill": {
     "duration": 0.024616,
     "end_time": "2023-04-01T04:56:56.428404",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.403788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have defined the preprocessing and required utils, let's load the `X` and `y` data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e0afe",
   "metadata": {
    "papermill": {
     "duration": 0.02475,
     "end_time": "2023-04-01T04:56:56.478297",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.453547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> As per the original notebook, in this case we do-not use $Z$ axis data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c935b",
   "metadata": {
    "papermill": {
     "duration": 0.025151,
     "end_time": "2023-04-01T04:56:56.528126",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.502975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Great, now we have two models, the first model has about 99% accuracy (remeber the val is part of the actual training set, so it's only a sanity check), and the second model is 82.5%. What does this mean? The first model definitely fits to the data better. \n",
    "\n",
    "> It also means that it's easier to overfit model-one compared to model-two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635fc72",
   "metadata": {
    "papermill": {
     "duration": 0.025424,
     "end_time": "2023-04-01T04:56:56.578591",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.553167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Final Inference Model & TFLITE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a72687",
   "metadata": {
    "papermill": {
     "duration": 0.025186,
     "end_time": "2023-04-01T04:56:56.628958",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.603772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's now create the final model that uses both the models - `model_one` and `model_two`. Remember model-1 is transformer based and model-2 is a simple fully-connected model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c031787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:56.681338Z",
     "iopub.status.busy": "2023-04-01T04:56:56.680958Z",
     "iopub.status.idle": "2023-04-01T04:56:56.690382Z",
     "shell.execute_reply": "2023-04-01T04:56:56.689412Z"
    },
    "papermill": {
     "duration": 0.038613,
     "end_time": "2023-04-01T04:56:56.692680",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.654067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FinalModel(tf.keras.Model):\n",
    "    def __init__(self, model, pp_layer):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.pp_layer = pp_layer\n",
    "        \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, cfg.N_ROWS, cfg.N_DIMS], dtype=tf.float32, name='inputs')])        \n",
    "    def __call__(self, inputs):\n",
    "        #model-2 (transformer)\n",
    "        x, non_empty_frame_idxs = self.pp_layer(inputs)\n",
    "        x = tf.expand_dims(x, axis=0)\n",
    "        non_empty_frame_idxs = tf.expand_dims(non_empty_frame_idxs, axis=0)\n",
    "        outputs = self.model({ 'frames': x, 'non_empty_frame_idxs': non_empty_frame_idxs })\n",
    "        outputs = tf.squeeze(outputs, axis=0)\n",
    "        \n",
    "        # Return a dictionary with the output tensor\n",
    "        return {'outputs': outputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67faef8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:56.745240Z",
     "iopub.status.busy": "2023-04-01T04:56:56.744865Z",
     "iopub.status.idle": "2023-04-01T04:56:56.755086Z",
     "shell.execute_reply": "2023-04-01T04:56:56.754105Z"
    },
    "papermill": {
     "duration": 0.039196,
     "end_time": "2023-04-01T04:56:56.757229",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.718033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_model = FinalModel(model, preprocess_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15729bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:56.809644Z",
     "iopub.status.busy": "2023-04-01T04:56:56.808554Z",
     "iopub.status.idle": "2023-04-01T04:56:58.032904Z",
     "shell.execute_reply": "2023-04-01T04:56:58.030886Z"
    },
    "papermill": {
     "duration": 1.253544,
     "end_time": "2023-04-01T04:56:58.036112",
     "exception": false,
     "start_time": "2023-04-01T04:56:56.782568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo_prediction: 232, correct: 232\n"
     ]
    }
   ],
   "source": [
    "demo_raw_data = load_relevant_data_subset(train['file_path'].values[1])\n",
    "demo_output = final_model(demo_raw_data)[\"outputs\"]\n",
    "demo_prediction = demo_output.numpy().argmax()\n",
    "print(f'demo_prediction: {demo_prediction}, correct: {train.iloc[1][\"sign_ord\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9727d758",
   "metadata": {
    "papermill": {
     "duration": 0.02509,
     "end_time": "2023-04-01T04:56:58.086777",
     "exception": false,
     "start_time": "2023-04-01T04:56:58.061687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "548e1f4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:56:58.139666Z",
     "iopub.status.busy": "2023-04-01T04:56:58.138624Z",
     "iopub.status.idle": "2023-04-01T04:57:37.452104Z",
     "shell.execute_reply": "2023-04-01T04:57:37.451013Z"
    },
    "papermill": {
     "duration": 39.342872,
     "end_time": "2023-04-01T04:57:37.455048",
     "exception": false,
     "start_time": "2023-04-01T04:56:58.112176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open('./model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e48f1bc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:57:37.508646Z",
     "iopub.status.busy": "2023-04-01T04:57:37.508239Z",
     "iopub.status.idle": "2023-04-01T04:57:38.563548Z",
     "shell.execute_reply": "2023-04-01T04:57:38.562253Z"
    },
    "papermill": {
     "duration": 1.085398,
     "end_time": "2023-04-01T04:57:38.566691",
     "exception": false,
     "start_time": "2023-04-01T04:57:37.481293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5M\t./model.tflite\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh ./model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e66f242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-01T04:57:38.620352Z",
     "iopub.status.busy": "2023-04-01T04:57:38.619160Z",
     "iopub.status.idle": "2023-04-01T04:57:39.818880Z",
     "shell.execute_reply": "2023-04-01T04:57:39.817259Z"
    },
    "papermill": {
     "duration": 1.229624,
     "end_time": "2023-04-01T04:57:39.822023",
     "exception": false,
     "start_time": "2023-04-01T04:57:38.592399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model.tflite (deflated 13%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip submission.zip ./model.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7387cfb",
   "metadata": {
    "papermill": {
     "duration": 0.026409,
     "end_time": "2023-04-01T04:57:39.875577",
     "exception": false,
     "start_time": "2023-04-01T04:57:39.849168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 130.950294,
   "end_time": "2023-04-01T04:57:43.327070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-01T04:55:32.376776",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0077e3e608434e5bb1420d456a4bc127": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0078e9dfccd84642a63ac8321add058f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a84169814c0c47678b43b460b12a68cd",
       "placeholder": "​",
       "style": "IPY_MODEL_66d5e84691d94b4c982831d9a27fc0fa",
       "value": " 40/40 [00:03&lt;00:00, 12.33it/s]"
      }
     },
     "11eaf751e54d4e8e879c8b7258b1ef88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3862f763099d40fc9784f4337a5a2095",
        "IPY_MODEL_db22978414f44d99b8d2f1c963f8eec0",
        "IPY_MODEL_b0fd6bdfb5ee4533a839adbf8cf5fe6c"
       ],
       "layout": "IPY_MODEL_860a361fabfe4c0fb4ecc0bce357e4d8"
      }
     },
     "1f11db0a43374aa6b1123a1d40bc10d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "25e9e1ed26da4154b95ddf3fb1dc937f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2e1602011454f6e9fdcaa23a72f6750",
       "max": 42.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1f11db0a43374aa6b1123a1d40bc10d9",
       "value": 42.0
      }
     },
     "2852084f0bbe44d4ba87f147ee16e6d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_efbd4781674a4fd08454ea87115858fe",
        "IPY_MODEL_25e9e1ed26da4154b95ddf3fb1dc937f",
        "IPY_MODEL_65a9a6f8d8da4a439b0a123158e08464"
       ],
       "layout": "IPY_MODEL_0077e3e608434e5bb1420d456a4bc127"
      }
     },
     "2d709b7e1f354d02b54233505bae6b94": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f2a9f388f8545469d7b7a6156bef9c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3204ce1518b6460093e56c5046ae9016": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3862f763099d40fc9784f4337a5a2095": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d709b7e1f354d02b54233505bae6b94",
       "placeholder": "​",
       "style": "IPY_MODEL_82c0f0f970d84ea181e59c005b28b543",
       "value": "100%"
      }
     },
     "503d29b628fb4b79a1734bebee70e16e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "59c4c40a12d2426696a7ca1e04dbe871": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65a9a6f8d8da4a439b0a123158e08464": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59c4c40a12d2426696a7ca1e04dbe871",
       "placeholder": "​",
       "style": "IPY_MODEL_bb7488a1cf5e4c98a1c2d9d6b4334040",
       "value": " 42/42 [00:02&lt;00:00, 13.98it/s]"
      }
     },
     "66d5e84691d94b4c982831d9a27fc0fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7f0028937c71414c8fb848ba0201069e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "81c81040698a4d338ea40cc4a9951a09": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82c0f0f970d84ea181e59c005b28b543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "860a361fabfe4c0fb4ecc0bce357e4d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a66cf28c41e543b394918864a513ecb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a84169814c0c47678b43b460b12a68cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0fd6bdfb5ee4533a839adbf8cf5fe6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81c81040698a4d338ea40cc4a9951a09",
       "placeholder": "​",
       "style": "IPY_MODEL_a66cf28c41e543b394918864a513ecb6",
       "value": " 10/10 [00:00&lt;00:00, 12.22it/s]"
      }
     },
     "b2e1602011454f6e9fdcaa23a72f6750": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b651ce4d609a428da76f1a33b6c10960": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6a7257b3b8a4df1b31bbc8521f5d25b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb7488a1cf5e4c98a1c2d9d6b4334040": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c841bcb2279341c9bbb628443e0dab54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbb839b408084bd4901b1c49a2d78a8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f0028937c71414c8fb848ba0201069e",
       "placeholder": "​",
       "style": "IPY_MODEL_503d29b628fb4b79a1734bebee70e16e",
       "value": "100%"
      }
     },
     "d4978464b71346b0b5fa7855a11dfcfb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cbb839b408084bd4901b1c49a2d78a8a",
        "IPY_MODEL_e4c6505f142d461eb63b8867eb9bcb2a",
        "IPY_MODEL_0078e9dfccd84642a63ac8321add058f"
       ],
       "layout": "IPY_MODEL_e6750fd007c541aba08977cef1cf3fec"
      }
     },
     "db22978414f44d99b8d2f1c963f8eec0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b651ce4d609a428da76f1a33b6c10960",
       "max": 10.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2f2a9f388f8545469d7b7a6156bef9c8",
       "value": 10.0
      }
     },
     "e4c6505f142d461eb63b8867eb9bcb2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b6a7257b3b8a4df1b31bbc8521f5d25b",
       "max": 40.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e4f13ce46af14b22af2bc31d39ccbf0f",
       "value": 40.0
      }
     },
     "e4f13ce46af14b22af2bc31d39ccbf0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e6750fd007c541aba08977cef1cf3fec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efbd4781674a4fd08454ea87115858fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c841bcb2279341c9bbb628443e0dab54",
       "placeholder": "​",
       "style": "IPY_MODEL_3204ce1518b6460093e56c5046ae9016",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
